# Cross-Modal-Integration-Image-Captioning-with-Multimodal-Pretrained-Models-and-Machine-Translation

## Abstract
This is a academic research focused on the image captioning and machine translation problems, approached in a fundamental and accessible manner. In this project, for the task image captioning, we utilize 7 pretrained models for image feature extraction: VGG16, VGG19, InceptionV3, ResNet50, EfficientNetV2L, DenseNet201, and InceptionResNetV2. These models are then combined with 2 sequence models, LSTM and GRU, resulting in a total of 14 model combinations aimed at comparing their effectiveness.

On the other hand, regarding of machine translation task, we utilized LSTM and GRU. Both models are trained on a dataset containing Vietnamese and English sentences, and are compared the performance with the Google Translate API. The purpose of our machine translation system, is to apply translations to caption sentences generated by the image captioning system. This will ultimately result in the creation of a bilingual image captioning system, seamlessly translating captions between Vietnamese and English.

## Dataset

**Image Captioning:**

Our evaluation was conducted on the UIT-ViIC dataset, comprising 3,850 images related to various ball sports. This dataset was curated from the 2017 version of the Microsoft COCO dataset and therefore, UITViIC also provides five Vietnamese captions for each image, resulting in a total of 19,250 captions.

Example:

- Image:

<img width="500" alt="Screenshot 2024-03-08 162739" src="https://github.com/motcapbovit/Cross-Modal-Integration-Image-Captioning-with-Multimodal-Pretrained-Models-and-Machine-Translation/assets/72774923/37658408-779a-4869-8cc7-939831106d76">

- Annotation:

<img width="500" alt="Screenshot 2024-03-08 162949" src="https://github.com/motcapbovit/Cross-Modal-Integration-Image-Captioning-with-Multimodal-Pretrained-Models-and-Machine-Translation/assets/72774923/cdf64048-4a84-4f38-91ba-24c81d732e87">
