# Cross Modal Integration Image Captioning with Multimodal Pretrained Models and Machine Translation

## Abstract
This is a academic research focused on the image captioning and machine translation problems, approached in a fundamental and accessible manner. In this project, for the task image captioning, we utilize 7 pretrained models for image feature extraction: VGG16, VGG19, InceptionV3, ResNet50, EfficientNetV2L, DenseNet201, and InceptionResNetV2. These models are then combined with 2 sequence models, LSTM and GRU, resulting in a total of 14 model combinations aimed at comparing their effectiveness.

On the other hand, regarding of machine translation task, we utilized LSTM and GRU. Both models are trained on a dataset containing Vietnamese and English sentences, and are compared the performance with the Google Translate API. The purpose of our machine translation system, is to apply translations to caption sentences generated by the image captioning system. This will ultimately result in the creation of a bilingual image captioning system, seamlessly translating captions between Vietnamese and English.

## Dataset

**Image Captioning:**

Our evaluation was conducted on the [UIT-ViIC dataset](https://sites.google.com/uit.edu.vn/uit-nlp/datasets?authuser=0), comprising 3,850 images related to various ball sports. This dataset was curated from the 2017 version of the Microsoft COCO dataset and therefore, UIT-ViIC also provides five Vietnamese captions for each image, resulting in a total of 19,250 captions.

Example:

- Image:

<img width="500" alt="Screenshot 2024-03-08 162739" src="https://github.com/motcapbovit/Cross-Modal-Integration-Image-Captioning-with-Multimodal-Pretrained-Models-and-Machine-Translation/assets/72774923/37658408-779a-4869-8cc7-939831106d76">

- Annotation:

<img width="500" alt="Screenshot 2024-03-08 162949" src="https://github.com/motcapbovit/Cross-Modal-Integration-Image-Captioning-with-Multimodal-Pretrained-Models-and-Machine-Translation/assets/72774923/cdf64048-4a84-4f38-91ba-24c81d732e87">

**Machine Translation:**

We leveraged caption sentences in both [Vietnamese](https://www.kaggle.com/datasets/trungit/flickr8k-vi-caps?resource=download) and [English](https://www.kaggle.com/datasets/adityajn105/flickr8k), which used to described images from the Flickr8k dataset. Subsequently, we adjusted the data structure to optimize it for the training process, resulting in a corpus comprising 4,000 sentences for each language.

Example:

<img width="500" alt="Screenshot 2024-03-08 211942" src="https://github.com/motcapbovit/Cross-Modal-Integration-Image-Captioning-with-Multimodal-Pretrained-Models-and-Machine-Translation/assets/72774923/4c4adc43-d9d9-430e-a697-1dcfe682d03d">

## Model Evaluation

**Image Captioning:**

<img width="500" alt="Screenshot 2024-03-08 163306" src="https://github.com/motcapbovit/Cross-Modal-Integration-Image-Captioning-with-Multimodal-Pretrained-Models-and-Machine-Translation/assets/72774923/fe4808bf-e091-4869-a737-36b2b8ad2b99">

**Machine Translation:**

<img width="500" alt="Screenshot 2024-03-08 203132" src="https://github.com/motcapbovit/Cross-Modal-Integration-Image-Captioning-with-Multimodal-Pretrained-Models-and-Machine-Translation/assets/72774923/b069d575-1f9a-4dce-9eb5-e363e598d4a1">

## Contact
Chi Thanh Dang, Thuy Hong Thi Dang and Tien Duong Pham

Faculty of Information Science and Engineering, University of Information Technology, Vietnam National University, Ho Chi Minh City, Vietnam.

20520761@gm.uit.edu.vn, 20520523@gm.uit.edu.vn, 20521222@gm.uit.edu.vn
